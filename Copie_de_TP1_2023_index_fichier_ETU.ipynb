{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N-nolwenn/SAM/blob/main/Copie_de_TP1_2023_index_fichier_ETU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAM: TP1 Accès aux données avec index \n",
        "\n",
        "Sujet pour étudiants\n",
        "\n",
        "date de modification : 26/01/2023 16h\n",
        "\n",
        "NOM: BOUCHOUCHI et PIGEON\n",
        "\n",
        "Prénom: Nour et Nolwenn"
      ],
      "metadata": {
        "id": "vZzLUr_l_Wfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectifs:\n",
        "Savoir organiser des données en pages pour permettre de modifier un tuple en ne modifiant qu'une seule page.\n",
        "\n",
        "Comprendre les méthodes d'accès suivantes :\n",
        "\n",
        "*   Lecture séquentielle d'un fichier : \"table access full\"\n",
        "*   Lecture d'un tuple dont on connait le rowid : \"table access by index rowid\"\n",
        "*   Opération de sélection par lecture séquentielle et filtrage \n",
        "\n",
        "Comprendre les méthodes d'indexation :\n",
        "\n",
        "*   Créer un index\n",
        "*   Opération de Sélection par index et lecture par rowid\n",
        "\n",
        "Mise à jour de données\n",
        "*   Sélectionner un tuple et modifier un de ses attributs\n",
        "*   Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n",
        "\n",
        "Persistence\n",
        "*   Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n",
        "*   Adapter en conséquence les opérations de modification de l'index\n"
      ],
      "metadata": {
        "id": "4TJrAm4JFr9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil as sh\n",
        "import numpy as np\n",
        "import random\n",
        "from random import choice\n",
        "from string import ascii_lowercase\n",
        "import time\n",
        "\n",
        "DATA = \"data.csv\""
      ],
      "metadata": {
        "id": "aodlGU01gLqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Générer un fichier"
      ],
      "metadata": {
        "id": "cRKX2fgx_gYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création du fichier"
      ],
      "metadata": {
        "id": "ezxoKUCxtASX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dure environ 40s pour 5M lignes\n",
        "\n",
        "nb_lines = 5 * 1000 * 1000\n",
        "# nb_lines = 100\n",
        "nb_attributes = 7\n",
        "\n",
        "longueur_attribut = 100\n",
        "# string_val = \"\".join(choice(ascii_lowercase) for i in range(longueur_attribut))\n",
        "long_string = ''.join('-' for i in range(longueur_attribut))\n",
        "\n",
        "# a=[np.random.randint(0, int(nb_lines/(10**i)), nb_lines) for i in range(nb_attributes)]\n",
        "nb_valeurs_distinctes = nb_lines\n",
        "\n",
        "# le premier attribut est unique\n",
        "a = [random.sample(range(nb_valeurs_distinctes), nb_lines)]\n",
        "\n",
        "# les attributs suivants ont des domaines plus petits\n",
        "for i in range(1, nb_attributes):\n",
        "  nb_valeurs_distinctes = max(2, int(nb_valeurs_distinctes / 2))\n",
        "  a.append(np.random.randint(0, nb_valeurs_distinctes, nb_lines))\n",
        "\n",
        "b = [ ','.join(map(lambda x: str(x), e)) + f\",{long_string}\\n\" for e in zip(*a)]\n",
        "\n",
        "with open(DATA, \"w\") as f:\n",
        "  f.write(''.join(b))"
      ],
      "metadata": {
        "id": "TIvmnhsTryK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "echo \"head : \"\n",
        "head -n 2 data.csv\n",
        "echo \"tail : \"\n",
        "tail -n 2 data.csv\n",
        "echo \"size (lines) :\"\n",
        "wc -l data.csv"
      ],
      "metadata": {
        "id": "1aMC3Y6yryK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea84996-e84a-40f6-f32a-d29ab9fff6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head : \n",
            "4095788,839448,70080,109550,136796,68306,2466,----------------------------------------------------------------------------------------------------\n",
            "4854203,296038,1245304,503837,93537,120020,59026,----------------------------------------------------------------------------------------------------\n",
            "tail : \n",
            "4846748,644656,266033,430815,312021,81213,72992,----------------------------------------------------------------------------------------------------\n",
            "4915570,626202,101139,122073,211216,145179,76573,----------------------------------------------------------------------------------------------------\n",
            "size (lines) :\n",
            "5000000 data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture séquentielle"
      ],
      "metadata": {
        "id": "5gm8_3CY_odp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filtrer_fichier(fichier, valeur_recherchee):\n",
        "  with open(fichier, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "      a = int(line.split(',')[0]) #cle unique\n",
        "      if a == s :\n",
        "        print(f\"ligne {i} :\", line.strip())\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_fichier(DATA, s)\n",
        "print(\"done in\", time.time() - t1, \"s\")"
      ],
      "metadata": {
        "id": "nSX2XxLx_tBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a80536-8700-42d8-a347-837ec052e175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valeur recherchée : 38823\n",
            "ligne 665558 : 38823,2437778,946775,101250,303476,74688,54533,----------------------------------------------------------------------------------------------------\n",
            "done in 4.552480697631836 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Découper le fichier en pages"
      ],
      "metadata": {
        "id": "qlmFE3aZTBWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def page_dir_name(fichier):\n",
        "  return fichier.split('.')[0] + \"_pages\"\n",
        "\n",
        "def decoupe_fichier_en_pages(fichier, nb_tuple_par_page):\n",
        "  page_dir = page_dir_name(fichier)\n",
        "  print(\"pages dans :\", page_dir)\n",
        "  if(os.path.exists(page_dir)):\n",
        "    sh.rmtree(page_dir)\n",
        "  os.makedirs(page_dir, exist_ok=True)\n",
        "\n",
        "  with open(fichier, \"r\") as f:\n",
        "    p=0\n",
        "    lines = []\n",
        "    for i, line in enumerate(f):\n",
        "      lines.append(line)\n",
        "      if (i+1) % nb_tuple_par_page == 0:\n",
        "        p += 1\n",
        "        with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "          fp.write(''.join(lines))\n",
        "        lines = []\n",
        "    if len(lines) > 0:\n",
        "      p +=1\n",
        "      with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "          fp.write(''.join(lines))\n",
        "    \n",
        "    print(\"nb pages créées :\", p)\n",
        "\n",
        "decoupe_fichier_en_pages(DATA, nb_tuple_par_page=1000)"
      ],
      "metadata": {
        "id": "kOEddKG8PHDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16c2124-dd82-42b7-c0b8-1cf9ceb1a3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pages dans : data_pages\n",
            "nb pages créées : 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afficher le nombre de tuples dans une page (pour quelques pages)"
      ],
      "metadata": {
        "id": "hqaml72_bXkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wc -l data_pages/* | head -n 3"
      ],
      "metadata": {
        "id": "qEX48QWEClJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a9fc4f-e616-45f3-d553-c902379ff4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     1000 data_pages/page1\n",
            "     1000 data_pages/page10\n",
            "     1000 data_pages/page100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture séquentielle du fichier découpé en pages"
      ],
      "metadata": {
        "id": "Y4XDZAmbcUQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lecture_sequentielle_par_page(fichier):\n",
        "   page_dir = page_dir_name(fichier)\n",
        "   nb_pages = len(os.listdir(page_dir))\n",
        "   \n",
        "   # a faire : pour chaque page, lire ses lignes\n",
        "   # une ligne devient un tuple\n",
        "   # retourner un itérateur contenant le numéro de page, la position dans la page et le tuple\n",
        "   for p in range(nb_pages) :\n",
        "     with open(page_dir + f\"/page{(p+1)}\", \"r\") as fp:\n",
        "       for i, line in enumerate(fp):\n",
        "         t = line.split(',')\n",
        "         yield p+1,i+1,t\n",
        "   \n",
        "\n",
        "\n",
        "def filtrer_fichier_par_pages(fichier, valeur_recherchee):\n",
        "  # à faire pour chaque (numéro de page, position dans la page, tuple) obtenu en invoquant la méthode ci-dessus\n",
        "  # convertir le 1er attribut en un nombre l'afficher si il est egal à la valeur recherchee  \n",
        "  y = lecture_sequentielle_par_page(fichier)\n",
        "  for line in y:\n",
        "    a = int(line[2][0])\n",
        "    if a == valeur_recherchee : \n",
        "      print(line)\n",
        "\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_fichier_par_pages(\"data.txt\", s)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ],
      "metadata": {
        "id": "fPVOrVpKccUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757f3f76-7390-4713-ee81-5748e3341463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valeur recherchée : 70171\n",
            "(3389, 332, ['70171', '244596', '723156', '64265', '273561', '87702', '26104', '----------------------------------------------------------------------------------------------------\\n'])\n",
            "done in 5.48 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture d'un tuple dans une page"
      ],
      "metadata": {
        "id": "UcmdLaQ5ruBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lecture_tuple(fichier, num_page, position):\n",
        "  page_dir = page_dir_name(fichier)\n",
        "  with open(page_dir + f\"/page{num_page}\", \"r\") as fp:\n",
        "    for i, line in enumerate(fp):\n",
        "      if(i==position-1):\n",
        "        #print(line)  \n",
        "        return line\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "lecture_tuple(\"data.txt\", 188,6)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ],
      "metadata": {
        "id": "F4tYi4xCrxFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65335e4e-c3ee-46af-858d-574f7b20366d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 0.0 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Créer un index"
      ],
      "metadata": {
        "id": "5mD_xZjLxXLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def creation_index_unique(fichier):\n",
        "  index = {}\n",
        "\n",
        "  # la clé est la valeur du 1er attribut\n",
        "  # la valeur est un rowid composé de (page, position)\n",
        "  y = lecture_sequentielle_par_page(fichier)\n",
        "\n",
        "  for line in y : \n",
        "    index[int(line[2][0])] = (line[0], line[1])\n",
        "  return index\n",
        "\n",
        "t1 = time.time()\n",
        "index1 = creation_index_unique(\"data.txt\")\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ],
      "metadata": {
        "id": "Fhy4IJ0bxWHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ce62a9-8d74-4cd2-b97c-42b09700ee9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 11.25 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def creation_index_not_unique(fichier):\n",
        "  index = {}\n",
        "\n",
        "  # la clé est la valeur du 1er attribut\n",
        "  # la valeur est un rowid composé de (page, position)\n",
        "  y = lecture_sequentielle_par_page(fichier)\n",
        "\n",
        "  for line in y :\n",
        "    if(int(line[2][1]) in index):\n",
        "      index[int(line[2][1])] = index[int(line[2][1])]+[(line[0], line[1])]\n",
        "    else : \n",
        "      index[int(line[2][1])] = [(line[0], line[1])]\n",
        "  return index\n",
        "\n",
        "t1 = time.time()\n",
        "index2 = creation_index_not_unique(\"data.txt\")\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjttUytmfC69",
        "outputId": "4c279b4c-0091-4276-85aa-1ca54a025822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 57.73 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(index1[3241396])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "povbCNs8gKl_",
        "outputId": "15be1942-49fb-4c34-e1f4-6b470c6f5a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(673, 646)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(index2[2466832])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESE9eLpWgZHu",
        "outputId": "9997ed7c-09b3-4d27-ab99-6a60ea947055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(860, 126), (2421, 628), (3426, 825)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accès par index"
      ],
      "metadata": {
        "id": "-qA7hCef5Kfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index unique scan\n",
        "Accès pour rechercher les tuples dont le 1er attribut a une valeur donnée.\n",
        "\n",
        "On peut supposer pour simplifier que l'attribut est unique"
      ],
      "metadata": {
        "id": "J0zrHPfGJjzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def selection_par_index(fichier, index, valeur_recherchee):\n",
        "  num_page, position = index[valeur_recherchee]\n",
        "  return lecture_tuple(fichier, num_page, position)\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "selection_par_index(\"data.txt\", index1, s)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ],
      "metadata": {
        "id": "PH3f5bz-5JTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3091d41c-bc9b-49c1-b014-28687f1b2e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valeur recherchée : 15851\n",
            "done in 0.0 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index range scan\n",
        "Accès pour rechercher les tuples dont le 1er attribut a une valeur comprise dans une intervalle donné"
      ],
      "metadata": {
        "id": "afvN2LWhJs0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def selection_par_index_plage(fichier, index, borne_inf, borne_sup):  \n",
        "  for i in range(borne_inf, borne_sup+1):\n",
        "    num_page, position = index[i]\n",
        "    lecture_tuple(fichier, num_page, position)\n",
        "\n"
      ],
      "metadata": {
        "id": "EGEO1PheSEdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "selection_par_index_plage(\"data.txt\", index1, 17000, 17030)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ],
      "metadata": {
        "id": "UEKExgGfKRUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ea86f8-993a-44e2-fad8-abe53d8866dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 0.01 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mise à jour de données\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7Rjm99DrKR8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sélectionner un tuple et modifier un de ses attributs\n",
        "\n"
      ],
      "metadata": {
        "id": "7np5NI8OKK6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def addN(a0, N):\n",
        "  \"\"\"\n",
        "  Dans la ligne correspondant à a0 on ajoute N à l'élément a1.\n",
        "  \"\"\"\n",
        "  page_dir = page_dir_name(DATA)\n",
        "  num_page, position = index1[a0]\n",
        "\n",
        "  lines=[]\n",
        "  with open(page_dir + f\"/page{num_page}\", \"r\") as fpr:\n",
        "    for i, line in enumerate(fpr):\n",
        "      if(i==position-1):\n",
        "        t = line.split(',')\n",
        "        t[1]=str(int(t[1])+N)\n",
        "        t=','.join(t)\n",
        "        lines.append(t)\n",
        "      else : \n",
        "        lines.append(line)\n",
        "\n",
        "  with open(page_dir + f\"/page{num_page}\", \"w\") as fpw:\n",
        "            fpw.write(''.join(lines))\n"
      ],
      "metadata": {
        "id": "RCRwCGlwKlEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#addN(844431,1)"
      ],
      "metadata": {
        "id": "u16BtidM13Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n"
      ],
      "metadata": {
        "id": "8zAZws5_KaL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def updateIndex2(fichier, a0, N):\n",
        "  \"\"\"\n",
        "  Mise à jour dans index2 (index non unique) suite aux modification sur a1 faites dans l'index1 avec la fonction addN\n",
        "  \"\"\"\n",
        "  num_page, position = index1[a0]\n",
        "  print(\"tuple après modification: \")\n",
        "  t = selection_par_index(fichier, index1, a0)\n",
        "  t = t.split(',')\n",
        "  new_a1 = int(t[1])\n",
        "  old_a1 = new_a1 - N\n",
        "  #suppression \n",
        "  values = index2.pop(old_a1)\n",
        "  values.pop(values.index((num_page,position)))\n",
        "  index2[old_a1] = values\n",
        "  #ajout\n",
        "  if(new_a1 in index2):\n",
        "    index2[new_a1] = index2[new_a1]+[(num_page, position)]\n",
        "  else : \n",
        "    index2[new_a1] = [(num_page, position)]\n",
        "\n"
      ],
      "metadata": {
        "id": "3_dcGN_dKaya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a0 = 1405205\n",
        "\n",
        "print(\"Avant : \")\n",
        "t = selection_par_index(DATA, index1, a0)\n",
        "t = t.split(',')\n",
        "old_a1 = int(t[1])\n",
        "print(index2[old_a1])\n",
        "\n",
        "addN(a0,1)\n",
        "updateIndex2(DATA, a0, 1)\n",
        "new_a1 = old_a1 + 1\n",
        "\n",
        "print(\"Après : \")\n",
        "print(index2[old_a1])\n",
        "print(index2[new_a1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWsfzqvl4dlT",
        "outputId": "8e230065-acc4-4390-8ac5-ad6d94382ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avant : \n",
            "[(3697, 723), (4639, 277)]\n",
            "tuple après modification: \n",
            "Après : \n",
            "[(3697, 723)]\n",
            "[(1892, 153), (2416, 468), (4639, 277)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Persistence\n",
        "\n",
        "Dans cette partie, on veut rendre les index persistents en les stockant dans des pages. Cela permet d'utiliser les index plus efficacement sans les recréer entièrement.\n"
      ],
      "metadata": {
        "id": "as_W7xmOKc3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n",
        "\n",
        "Proposer une solution pour stocker les entrées triées d'un index unique dans plusieurs pages avec une taille de page fixée (500 entrées par page,  soit 500 clés + 500 rowid)."
      ],
      "metadata": {
        "id": "Uy8NE3x5KgLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stockIndex(index):\n",
        "\n",
        "  if(os.path.exists(\"indexUnique_pages\")):\n",
        "    sh.rmtree(\"indexUnique_pages\")\n",
        "  os.makedirs(\"indexUnique_pages\")\n",
        "\n",
        "  nb_entree_par_page = 500\n",
        "\n",
        "  lines = []\n",
        "  i=0\n",
        "  p=0\n",
        "  for key in sorted(index.keys()):\n",
        "    lines.append(str(key)+' '+str(index[key][0])+' '+str(index[key][1]))\n",
        "      \n",
        "    # créer une page\n",
        "    if (i+1) % nb_entree_par_page == 0:\n",
        "      p += 1\n",
        "      with open(\"indexUnique_pages\" + f\"/page{p}\", \"w\") as fp:\n",
        "        fp.write('\\n'.join(lines))\n",
        "      lines = []\n",
        "    \n",
        "    i+=1\n",
        "  \n",
        "  # créer une dernière page, si nécessaire\n",
        "  if len(lines) > 0:\n",
        "    p +=1\n",
        "    with open(\"indexUnique_pages\" + f\"/page{p}\", \"w\") as fp:\n",
        "        fp.write('\\n'.join(lines))\n",
        "  \n",
        "  return p \n",
        "\n",
        "nb_pages_index_unique = stockIndex(index1)"
      ],
      "metadata": {
        "id": "VqSClCOgKl6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stockage d'un index non unique\n",
        "Proposer une solution pour stocker les entrées triées d'un index non unique dans plusieurs pages avec une taille de page fixée. Dans une page, le total du nombre  de clés + le nombre de rowid ne peut pas dépasser 1000."
      ],
      "metadata": {
        "id": "kMdY5AEKN3WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stockIndexNonUnique(index):\n",
        "  if(os.path.exists(\"indexNonUnique_pages\")):\n",
        "    sh.rmtree(\"indexNonUnique_pages\")\n",
        "  os.makedirs(\"indexNonUnique_pages\")\n",
        "\n",
        "  nb_cle_et_rowid_par_page = 1000\n",
        "\n",
        "  lines = []\n",
        "  k=0\n",
        "  r=0\n",
        "  p=0\n",
        "  for key in sorted(index.keys()):\n",
        "    s=''\n",
        "    for v in index[key]:\n",
        "      s += str(v[0])+' '+str(v[1])+' '\n",
        "    lines.append(str(key)+' '+s)\n",
        "      \n",
        "    # créer une page\n",
        "    if (k+r+1) % nb_cle_et_rowid_par_page == 0:\n",
        "      p += 1\n",
        "      with open(\"indexNonUnique_pages\" + f\"/page{p}\", \"w\") as fp:\n",
        "        fp.write('\\n'.join(lines))\n",
        "      lines = []\n",
        "    \n",
        "    k+=1\n",
        "    r+=len(index[key])\n",
        "  \n",
        "  # créer une dernière page, si nécessaire\n",
        "  if len(lines) > 0:\n",
        "    p +=1\n",
        "    with open(\"indexNonUnique_pages\" + f\"/page{p}\", \"w\") as fp:\n",
        "        fp.write('\\n'.join(lines))\n",
        "  \n",
        "  return p\n",
        "\n",
        "nb_pages_index_non_unique = stockIndexNonUnique(index2)"
      ],
      "metadata": {
        "id": "FlvQblrTN5aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adapter en conséquence les opérations de modification de l'index"
      ],
      "metadata": {
        "id": "SzDPXcGzKjKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On cherche à adapter ce que l'on a fait précédemment.\n",
        "On souhaite modifier les index suite à l'ajout de N à a1 (à partir de a0).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xbaRlNk4Zvtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findPageIndexUnique(a0_rech):\n",
        "  for p in range(nb_pages_index_unique):\n",
        "    a=lecture_tuple(\"indexUnique\", p+1,1)\n",
        "    a=a.split(' ')\n",
        "    a0 = a[0]\n",
        "    if(int(a0)>int(a0_rech)):\n",
        "      return p\n",
        "  return nb_pages_index_unique #la dernière page\n"
      ],
      "metadata": {
        "id": "fEmGKO_Qalys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findPageIndexNonUnique(a1_rech):\n",
        "  for p in range(nb_pages_index_non_unique):\n",
        "    a=lecture_tuple(\"indexNonUnique\", p+1,1)\n",
        "    a=a.split(' ')\n",
        "    a1 = a[0]\n",
        "    if(int(a1)>int(a1_rech)):\n",
        "      return p\n",
        "  return nb_pages_index_non_unique #la dernière page\n"
      ],
      "metadata": {
        "id": "EEY5cJVvd3CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findRowidIndexUnique(a0_rech):\n",
        "  p = findPageIndexUnique(a0_rech)\n",
        "  with open(\"indexUnique_pages\" + f\"/page{p}\", \"r\") as fp:\n",
        "    for i, line in enumerate(fp):\n",
        "      t = line.split(' ')\n",
        "      if(int(t[0])==a0_rech):\n",
        "        return t[1],str(int(t[2])-1)\n",
        "  return -1 #si on n'a pas trouvé le a0_rech\n"
      ],
      "metadata": {
        "id": "iW3UlFXucwi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findRowidIndexNonUnique(a1_rech):\n",
        "  p = findPageIndexNonUnique(a1_rech)\n",
        "  with open(\"indexNonUnique_pages\" + f\"/page{p}\", \"r\") as fp:\n",
        "    for i, line in enumerate(fp):\n",
        "      t = line.split(' ')\n",
        "      if(int(t[0])==a1_rech):\n",
        "        return t[1:-1]\n",
        "  return -1 #si on n'a pas trouvé le a1_rech"
      ],
      "metadata": {
        "id": "WPt1s6hej9mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addN_bis(a0,N):\n",
        "  #récupérer le rowid de a0 (findRowidIndexUnique)\n",
        "  page, position = findRowidIndexUnique(a0)\n",
        "  print(\"page et position de a0 : \", (int(page),int(position)))\n",
        "\n",
        "  #modifier le a1 correpondant à a0 à la (page, position) correspondante\n",
        "  old_a1 = -1\n",
        "  new_a1 = -1\n",
        "  page_dir = page_dir_name(DATA)\n",
        "  lines=[]\n",
        "  with open(page_dir + f\"/page{page}\", \"r\") as fpr:\n",
        "    for i, line in enumerate(fpr):\n",
        "      if(i==int(position)-2):\n",
        "        t = line.split(',')\n",
        "        old_a1 = t[1]\n",
        "        t[1]=str(int(t[1])+N)\n",
        "        new_a1 = t[1]\n",
        "        t=','.join(t)\n",
        "        lines.append(t)\n",
        "      else : \n",
        "        lines.append(line)\n",
        "\n",
        "  with open(page_dir + f\"/page{page}\", \"w\") as fpw:\n",
        "      fpw.write(''.join(lines))\n",
        "\n",
        "  #récupérer le/les rowid de l'ancienne et de la nouvelle valeur de a1\n",
        "  old_a1_rowid = findRowidIndexNonUnique(int(old_a1))\n",
        "  new_a1_rowid = findRowidIndexNonUnique(int(new_a1))   \n",
        "  print(\"Anciens Rowid pour a1 (ancien et nouveau): \")\n",
        "  print(str(old_a1)+' : ',old_a1_rowid)\n",
        "  print(str(new_a1)+' : ',new_a1_rowid)\n",
        "\n",
        "  #enlève le rowid de l'ancienne valeur de a1\n",
        "  for i in range(len(old_a1_rowid)-2): \n",
        "    if(int(old_a1_rowid[i])==int(page) and int(old_a1_rowid[i+1])==int(position)-1):\n",
        "      old_a1_rowid.pop(i)\n",
        "      old_a1_rowid.pop(i)\n",
        "  lines=[]\n",
        "  page_old_a1 = findPageIndexNonUnique(old_a1)\n",
        "  with open(\"indexNonUnique_pages\" + f\"/page{page_old_a1}\", \"r\") as fpr:\n",
        "    for i, line in enumerate(fpr):\n",
        "      t = line.split(' ')\n",
        "      if(t[0]==old_a1):\n",
        "        print(old_a1_rowid)\n",
        "        lines.append(str(old_a1)+' '+' '.join(old_a1_rowid)+' \\n')\n",
        "      else :\n",
        "        lines.append(line)\n",
        "\n",
        "  with open(\"indexNonUnique_pages\" + f\"/page{page_old_a1}\", \"w\") as fpw:\n",
        "    fpw.write(''.join(lines))\n",
        "\n",
        "  #ajoute le rowid à la nouvelle valeur de a1\n",
        "  page_new_a1 = findPageIndexNonUnique(new_a1)\n",
        "  add_a1 = False\n",
        "  lines=[]\n",
        "  if(new_a1_rowid == -1): #cas où new_a1 n'existait pas \n",
        "    with open(\"indexNonUnique_pages\" + f\"/page{page_new_a1}\", \"r\") as fpr:\n",
        "      for i, line in enumerate(fpr):\n",
        "        t = line.split(' ')\n",
        "        if(add_a1==False):\n",
        "          if(t[0]>new_a1):\n",
        "            lines.append(str(new_a1)+' '+page+' '+position+' '+'\\n')\n",
        "            add_a1=True\n",
        "          lines.append(line)\n",
        "        else:\n",
        "          lines.append(line)\n",
        "\n",
        "    with open(\"indexNonUnique_pages\" + f\"/page{page_new_a1}\", \"w\") as fpw:\n",
        "      fpw.write(''.join(lines))\n",
        "\n",
        "\n",
        "  else : #cas où new_a1 existait déjà\n",
        "    with open(\"indexNonUnique_pages\" + f\"/page{page_new_a1}\", \"r\") as fpr:\n",
        "        for i, line in enumerate(fpr):\n",
        "          t = line.split(' ')\n",
        "          if(t[0]==new_a1):\n",
        "            lines.append(str(new_a1)+' '+' '.join(new_a1_rowid)+' '+page+' '+position+' '+'\\n')\n",
        "          else : \n",
        "            lines.append(line)\n",
        "\n",
        "    with open(\"indexNonUnique_pages\" + f\"/page{page_new_a1}\", \"w\") as fpw:\n",
        "      fpw.write(''.join(lines))\n",
        "\n",
        "  print(\"Anciens Rowid pour a1 (ancien et nouveau): \")\n",
        "  old_a1_rowid = findRowidIndexNonUnique(int(old_a1))\n",
        "  new_a1_rowid = findRowidIndexNonUnique(int(new_a1))   \n",
        "  print(str(old_a1)+' : ',old_a1_rowid)\n",
        "  print(str(new_a1)+' : ',new_a1_rowid)"
      ],
      "metadata": {
        "id": "y9mXqJeFKmUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "addN_bis(1487591, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UeQeLOOsxgo",
        "outputId": "7a3faa7d-5a99-4f0d-eb3a-adbfb2ec349e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page et position de a0 :  (1022, 126)\n",
            "Anciens Rowid pour a1 (ancien et nouveau): \n",
            "969405 :  ['84', '321', '167', '962', '1022', '125', '4737', '511']\n",
            "969406 :  ['820', '952', '2324', '434']\n",
            "['84', '321', '167', '962', '4737', '511']\n",
            "Anciens Rowid pour a1 (ancien et nouveau): \n",
            "969405 :  ['84', '321', '167', '962', '4737', '511']\n",
            "969406 :  ['820', '952', '2324', '434', '1022', '126']\n"
          ]
        }
      ]
    }
  ]
}